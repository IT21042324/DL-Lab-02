IT21042324 - Reezan S. A

1. Upload the Backprop.ipynb to Jupyter notebook (or google colab) and see if you can understand
the code. Increase the number of iterations (epochs) and see whether it improves the prediction
accuracy.

    Error seems to have reduced even further compared to 200 number of iterations. 
    Seems like with the given learning rate of 0.5 can do better with a larger number of 
    iterations when attmepting to calculate the minimum cost to find the best weights



2.Upload the NN_sample.ipynb to Jupyter notebook (or google colab) and see if you can
understand the code. Add the following text cell and the code cell to the notebook and run it
again.

    2.1. What happens when the number of hidden nodes increase?
	When the number of hidden nodes was set to a lower value, the accuracy was low, in the 60% range. This suggests that the model might not be complex enough to capture the relevant information, potentially leading to underfitting. However, as the number of hidden layers increased, we observed substantial growth in prediction accuracy, while the error rate decreased. This indicates that the model is effectively capturing the necessary information from the input data, increasing model complexity.

	However, when the number of hidden nodes exceeded a certain threshold (greater than 20), the accuracy began to fluctuate between 90% and 93%. This implies that the optimal model complexity may have been achieved within this range. Despite this, it's uncertain whether the model is overly complex, which could lead to overfitting.

	To address this, the model needs to be tested with a separate test dataset to assess its generalization performance. The appropriate number of hidden nodes should be determined based on the model's performance on this test data.



    2.2. Can you explain the pattern of the accuracy when the hidden nodes increase?
	Initially, as the number of hidden layers increased from 2 to 4, the model's accuracy improved significantly, rising from 67% to 90%. However, further increasing the number of hidden layers (from 4 to 10, 10 to 20, 20 to 50, and 50 to 70 layers) did not lead to substantial improvements, with accuracy fluctuating between 90% and 94%.

	This suggests that the model is achieving good training accuracy. However, adding more hidden layers may also increase the risk of overfitting due to the increased complexity of the model. Although training accuracy improves with more hidden units, the model's performance on unseen data is uncertain and could potentially be poor because of the added complexity.

